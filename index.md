
<div align=center>
<img src="/assets/img/lihu_avatar.jpeg" width="200px" />
</div>

<br>

[![GitHub](https://img.shields.io/badge/GitHub-%23121011.svg?logo=github&logoColor=white)](https://github.com/tigerchen52) 
[![Scholar](https://img.shields.io/badge/Google-4285F4?logo=google&logoColor=white)](https://scholar.google.com/citations?user=oRs8regAAAAJ&hl=en)
[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-FFD21E?logo=huggingface&logoColor=000)](https://huggingface.co/Lihuchen)
[![LinkedIn](https://img.shields.io/badge/Linkedin-%230077B5.svg?logo=linkedin&logoColor=white)](https://www.linkedin.com/in/lihu-chen-43482a284/)
[![X](https://img.shields.io/badge/X-%23000000.svg?logo=X&logoColor=white)](https://twitter.com/LihuChen)


___

ðŸ“¢ðŸ“¢ **News**

* Check out our survey about the role of small models in the LLM era <a href="https://arxiv.org/abs/2409.06857">
  <img src="https://img.shields.io/badge/PDF-arxiv-10868" alt="PDF Badge" width="50" height="13">
 </a> <a href="https://github.com/tigerchen52/role_of_small_models">
  <img src="https://img.shields.io/badge/GitHub-%23121011.svg?logo=github&logoColor=white" alt="PDF Badge" width="50" height="13"></a> <br>
* Our QR-Neuron is available: a package of extracting query-relevant neurons in LLMs <a href="https://github.com/tigerchen52/qrneuron">
  <img src="https://img.shields.io/badge/PDF-arxiv-10868" alt="PDF Badge" width="50" height="13">
 </a> <a href="https://github.com/tigerchen52/qrneuron">
  <img src="https://img.shields.io/badge/GitHub-%23121011.svg?logo=github&logoColor=white" alt="PDF Badge" width="50" height="13"></a>  <br>
* Our new version of [YAGO knowledge base](https://yago-knowledge.org/) is available, which is accepted by SIGIR 2024 <a href="https://dl.acm.org/doi/abs/10.1145/3626772.3657876"> 
  <img src="https://img.shields.io/badge/PDF-SIGIR-10868" alt="PDF Badge" width="50" height="13">
 </a> <br>
* Our PEARL is available on ðŸ¤— [HuggingFace](https://huggingface.co/Lihuchen/pearl_small), a lightweight and powerful embedding model for short texts <a href="https://huggingface.co/Lihuchen/pearl_small"> 
  <img src="https://img.shields.io/badge/Hugging%20Face-FFD21E?logo=huggingface&logoColor=000" alt="PDF Badge" width="50" height="13">
 </a> <br>

___

My name is Lihu Chen (é™ˆç«‹è™Ž), and I am currently a Research Associate at [Imperial College London](https://www.imperial.ac.uk/). 
Before that, I did a one-year postdoc at [Inria Saclay](https://www.inria.fr/en/inria-saclay-centre). I obtained my PhD at [DIG](https://dig.telecom-paris.fr/blog/) team of [TÃ©lÃ©com Paris](https://www.telecom-paris.fr/en/home), which is a member of [Institut Polytechnique de Paris](https://www.ip-paris.fr/en). I was co-supervised by [Fabian Suchanek](https://suchanek.name/) and [GaÃ«l Varoquaux](http://gael-varoquaux.info/). <br>

I am committed to developing efficient, trustworthy, and open-source models, with a focus on information extraction and biomedical applications. Specifically, my research topics include: 

* **Efficient Language Models**. Check out our small models for biomedical entity disambiguation ([AAAI 21](https://arxiv.org/pdf/2012.08844.pdf)), out-of-vocabulary words ([ACL 22](https://aclanthology.org/2022.acl-long.245.pdf)) and short text representations ([EACL 24](https://arxiv.org/pdf/2401.10407.pdf)) 
* **Information Extraction**.  I am interested in Entity Linking ([AAAI 21](https://arxiv.org/pdf/2012.08844.pdf), [EACL 23](https://aclanthology.org/2023.eacl-main.152.pdf)), Knowledge Base Construction ([SIGIR 24](https://suchanek.name/work/publications/sigir-2024.pdf)) and Completion ([ACL@Matching 23](https://aclanthology.org/2023.matching-1.8.pdf)) 
* **Interpretability of LLMs and Trustworthy Models**. The properties of positional encodings in Transformers ([EMNLP 23](https://aclanthology.org/2023.findings-emnlp.955.pdf)); Key neurons in LLMs ([Preprint 24](https://arxiv.org/pdf/2406.10868)); Mitigating Hallucinations of LLMs ([Preprint 24](https://arxiv.org/pdf/2402.04957.pdf))

___


### Misc
* My [Github](https://github.com/tigerchen52) 
* Human Language: Chinese Mandarin (Native); English (Fluent); French (Basic)
* [Travel Photos](https://chenlihu.com/blog/)

___

### Contact
**Email**:[firstname].[lastname][AT]imperial.ac.uk
