
<div align=center>
<img src="/assets/img/lihu_avatar.jpeg" width="200px" />
</div>

&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; ‚öâ **[Github](https://github.com/tigerchen52)**  üéì **[Scholar](https://scholar.google.com/citations?user=oRs8regAAAAJ&hl=en)** ü§ó **[Huggingface](https://huggingface.co/Lihuchen)** üë• **[LinkedIn](https://www.linkedin.com/in/lihu-chen-43482a284/)** üê¶ **[Twitter](https://twitter.com/LihuChen)** <br>

üì¢üì¢ **News**

* Our [keyneuron](https://github.com/tigerchen52/keyneuron) is released on test PYPI: a package of extracting key neurons in LLMs ([ArXiv Preprint](https://arxiv.org/abs/2406.10868))!
* Our new version of [YAGO knowledge base](https://yago-knowledge.org/) is available, which is accepted by SIGIR 2024!
* Our PEARL is available on ü§ó [HuggingFace](https://huggingface.co/Lihuchen/pearl_small), a lightweight and powerful embedding model for short texts!

___

My name is Lihu Chen (ÈôàÁ´ãËôé), and I am currently a Research Associate at [Imperial College London](https://www.imperial.ac.uk/). 
Before that, I did a one-year postdoc at [Inria Saclay](https://www.inria.fr/en/inria-saclay-centre). I obtained my PhD at [DIG](https://dig.telecom-paris.fr/blog/) team of [T√©l√©com Paris](https://www.telecom-paris.fr/en/home), which is a member of [Institut Polytechnique de Paris](https://www.ip-paris.fr/en). I was co-supervised by [Fabian Suchanek](https://suchanek.name/) and [Ga√´l Varoquaux](http://gael-varoquaux.info/). <br>

I am committed to developing efficient and trustworthy models, with a focus on information extraction and biomedical applications. Specifically, my research topics include: 

* **Efficient Language Models**. Check out our small models for biomedical entity disambiguation ([AAAI 21](https://arxiv.org/pdf/2012.08844.pdf)), out-of-vocabulary words ([ACL 22](https://aclanthology.org/2022.acl-long.245.pdf)) and short text representations ([EACL 24](https://arxiv.org/pdf/2401.10407.pdf)) 
* **Information Extraction**.  I am interested in Entity Linking ([AAAI 21](https://arxiv.org/pdf/2012.08844.pdf), [EACL 23](https://aclanthology.org/2023.eacl-main.152.pdf)), Knowledge Base Construction ([SIGIR 24](https://suchanek.name/work/publications/sigir-2024.pdf)) and Completion ([ACL@Matching 23](https://aclanthology.org/2023.matching-1.8.pdf)) 
* **Trustworthy Models**. I am interested in estimating uncertainty to mitigate hallucinations of LLMs. To this end, we analyze ([Preprint 24](https://arxiv.org/pdf/2402.04957.pdf)) 
* **Interpretability and Analysis of LLMs**. The properties of positional encodings ([EMNLP 23](https://aclanthology.org/2023.findings-emnlp.955.pdf)); Key neurons in LLMs ([Preprint 24](https://arxiv.org/pdf/2406.10868))

___


### Misc
* My [Github](https://github.com/tigerchen52) 
* Human Language: Chinese Mandarin (Native); English (Fluent); French (Basic)
* [Travel Photos](https://chenlihu.com/blog/)

___

### Contact
**Email**:[firstname].[lastname][AT]imperial.ac.uk
